{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sandbox.celine_knowledge_graph import *\n",
    "# from sandbox.spacy_experiments import *\n",
    "# from sandbox.neuralcoref_experiments import *\n",
    "# from bert_embedding import BertEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x14824ceb8>"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import spacy\n",
    "import neuralcoref\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_src(s):\n",
    "    s = s.split()\n",
    "    # remove everything from \"-lrb-\" to \"-rrb-\"\n",
    "    s2 = []\n",
    "    in_paren = False\n",
    "    for ixw, w in enumerate(s):\n",
    "        if(w==\"-lrb-\"):\n",
    "            in_paren=True\n",
    "        elif(w=='-rrb-'):\n",
    "            in_paren=False\n",
    "        elif(w==\"-lsb-\" or w==\"-rsb-\"):\n",
    "            continue\n",
    "        elif(len(w) > 1 and w[0] == '\\''):\n",
    "            s2[-1] = s2[-1]+w\n",
    "        elif not in_paren and not (w == '<t>' or w == '</t>'):\n",
    "            s2.append(w)\n",
    "    return ' '.join(s2)\n",
    "\n",
    "def clean_gen(s):\n",
    "    s = s.split()\n",
    "    # remove everything from \"-lrb-\" to \"-rrb-\"\n",
    "    s2 = []\n",
    "    in_paren = False\n",
    "    for w in s:\n",
    "        if(w==\"-lrb-\"):\n",
    "            in_paren=True\n",
    "        elif(w=='-rrb-'):\n",
    "            in_paren=False\n",
    "        elif(w==\"-lsb-\" or w==\"-rsb-\"):\n",
    "            continue\n",
    "        elif(len(w) > 1 and w[0] == '\\''):\n",
    "            s2[-1] = s2[-1]+w\n",
    "        elif not in_paren and not(w == '<t>' or w == '</t>'):\n",
    "            s2.append(w)\n",
    "    return ' '.join(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeGraph:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.relations = list()\n",
    "        self.noun_threshold = 0.9\n",
    "        self.verb_threshold = 0.9\n",
    "        self.entailment = 0\n",
    "        self.dissimilar_verbs = 1\n",
    "        self.missing_dependencies = 2\n",
    "        self.contradiction = 3\n",
    "\n",
    "    # ==========================================\n",
    "    # 1) adding to KnowledgeGraph relations \n",
    "    # ==========================================\n",
    "    def add_verb(self, verb):\n",
    "        self.relations.append(self.get_relation(verb))\n",
    "\n",
    "        \n",
    "    ##### extracting relations from sentence #####\n",
    "    def get_relation(self, verb):\n",
    "        # get all equivalent verbs\n",
    "        verb_cluster = self.get_verb_cluster(verb)\n",
    "        actors = []\n",
    "        acteds = []\n",
    "        \n",
    "        # get all actors/acteds of verbs in equivalencies\n",
    "        for verb in verb_cluster:\n",
    "            actors += self.get_actors(verb)\n",
    "            acteds += self.get_acteds(verb)\n",
    "#         print(\"relation\", verb_cluster, actors, acteds)\n",
    "        return verb_cluster, actors, acteds\n",
    "    \n",
    "    # =========================================\n",
    "    # 2) looks through verb's children for\n",
    "    # verb equivalencies (xcomp)\n",
    "    # =========================================\n",
    "    def get_verb_cluster(self, verb):\n",
    "        verb_cluster = [verb]\n",
    "        for child in verb.children:\n",
    "            if child.dep_ == \"xcomp\":# or child.dep_ == \"ccomp\":\n",
    "                verb_cluster.append(child)\n",
    "        return verb_cluster\n",
    "        \n",
    "    def get_actors(self, verb):\n",
    "        actors = []\n",
    "        for child in verb.children:\n",
    "            # child is a nominative subject\n",
    "            if child.dep_ == \"nsubj\":\n",
    "                actors.append(child)\n",
    "            # child is something like \"by\"\n",
    "            elif child.dep_ == \"agent\":  \n",
    "                # passive, look for true actor\n",
    "                for grandchild in child.children:\n",
    "                    if grandchild.dep_ == \"pobj\":\n",
    "                        actors.append(grandchild)\n",
    "        return actors\n",
    "\n",
    "    def get_acteds(self, verb):\n",
    "        acteds = []\n",
    "        for child in verb.children:\n",
    "            #child is direct object or passive subject\n",
    "            if child.dep_ == \"dobj\" or child.dep_ == \"nsubjpass\":\n",
    "                acteds.append(child)\n",
    "        return acteds\n",
    "\n",
    "    # =========================================\n",
    "    # 3) checking hypothesis relation against \n",
    "    # premise's KnowledgeGraph relations\n",
    "    # =========================================\n",
    "    def query_relation(self, hypothesis):\n",
    "        missing_dependencies = []\n",
    "        contradiction = []\n",
    "        for premise in self.relations:\n",
    "            r = self.implied_relation(premise, hypothesis)\n",
    "\n",
    "            # once we find that hypothesis is contained,\n",
    "            # accept this relation as verified\n",
    "            if r[0] == self.entailment:\n",
    "                return r[0], [(premise, r[1])]\n",
    "            elif r[0] == self.missing_dependencies:\n",
    "                missing_dependencies.append((premise, r[1]))\n",
    "            elif r[0] == self.contradiction:\n",
    "                contradiction.append((premise, r[1]))\n",
    "        if len(contradiction) > 0:\n",
    "            return self.contradiction, contradiction\n",
    "        return self.missing_dependencies, missing_dependencies\n",
    "    \n",
    "    # check if a hypothesis is verified by a premise \n",
    "    # returns (result, proof)\n",
    "    def implied_relation(self, premise, hypothesis):\n",
    "        # premise[0] and hypothesis[0] is a list (verb cluster)\n",
    "        verb_similarity, best_pair = self.verb_same(premise[0], hypothesis[0])\n",
    "        if verb_similarity < self.verb_threshold:\n",
    "            return self.dissimilar_verbs, hypothesis\n",
    "        \n",
    "        # check setminus of premise \\ hypothesis\n",
    "        actor_actor = self.noun_intersect_setminus(premise[1], hypothesis[1])\n",
    "        acted_acted = self.noun_intersect_setminus(premise[2], hypothesis[2])\n",
    "        actor_acted = self.noun_intersect_setminus(premise[1], hypothesis[2])\n",
    "        acted_actor = self.noun_intersect_setminus(premise[2], hypothesis[1])\n",
    "        \n",
    "        contained_deps = actor_actor[0] + acted_acted[0]\n",
    "        missing_deps = actor_actor[1] + acted_acted[1]\n",
    "        contradiction_deps = actor_acted[0] + acted_actor[0]\n",
    "        if len(missing_deps) == 0:\n",
    "            return self.entailment, (\"verb similarity:\", verb_similarity,\n",
    "                    \"contained dependences:\", contained_deps)\n",
    "        if len(contradiction_deps) > 0:\n",
    "            return self.contradiction, (\"verb similarity:\", verb_similarity,\n",
    "                    \"contradictory dependences:\", contradiction_deps)\n",
    "        return self.missing_dependencies, (\"verb similarity:\",\n",
    "                verb_similarity, \"missing dependencies:\", missing_deps)\n",
    "\n",
    "    \n",
    "    # ========================\n",
    "    # verb helper functions\n",
    "    # ========================\n",
    "    # v1 comes from premise/source, v2 comes from hypothesis/output\n",
    "    def verb_same(self, v1_cluster, v2_cluster):\n",
    "        maximum_similarity = 0\n",
    "        maximum_pair = None\n",
    "        for v1 in v1_cluster:\n",
    "            for v2 in v2_cluster:\n",
    "                similarity = v1.similarity(v2)\n",
    "                if(similarity > maximum_similarity):\n",
    "                    maximum_similarity = similarity\n",
    "                    maximum_pair = v1, v2\n",
    "        return maximum_similarity, maximum_pair\n",
    "    \n",
    "    \n",
    "#     # returns (result, proof)\n",
    "#     def query_verb(self, verb):\n",
    "#         return self.query_relation(self.get_relation(verb))\n",
    "\n",
    "\n",
    "    # ========================\n",
    "    # noun helper functions\n",
    "    # ========================\n",
    "    def noun_intersect_setminus(self, supset, subset):\n",
    "        contained_nouns = []\n",
    "        missing_nouns = []\n",
    "        for n in subset:\n",
    "            contained = False\n",
    "            for n2 in supset:\n",
    "                r = self.noun_same(n, n2)\n",
    "                if r[0]:\n",
    "                    contained = True\n",
    "                    contained_nouns.append((n, n2, r[1]))\n",
    "                    continue\n",
    "            if not contained:\n",
    "                missing_nouns.append(n)\n",
    "        return contained_nouns, missing_nouns\n",
    "\n",
    "    def noun_same(self, n1, n2):\n",
    "#         print(\"noun\", n1, n2)\n",
    "        spans1 = self.get_valid_cluster_objects(n1)\n",
    "        spans2 = self.get_valid_cluster_objects(n2)\n",
    "        maximum_similarity = 0\n",
    "        maximum_pair = None\n",
    "        for span1 in spans1:\n",
    "            for span2 in spans2:\n",
    "                try:\n",
    "                    span_similarity = span1.similarity(span2)\n",
    "                except:\n",
    "                    continue\n",
    "                if span_similarity > maximum_similarity:\n",
    "                    maximum_similarity = span_similarity\n",
    "                    maximum_pair = span1, span2\n",
    "        if maximum_similarity > self.noun_threshold:\n",
    "            return True, (\"best match:\", maximum_similarity, maximum_pair)\n",
    "        return False, (\"best match:\", maximum_similarity, maximum_pair)\n",
    "\n",
    "    def get_valid_cluster_objects(self, noun):\n",
    "        spans = list()\n",
    "        if (noun.pos_ == 'PRON' or noun.pos_ == 'DET') and noun.head.dep_ == 'relcl':\n",
    "            # the head is the verb of the relative clause\n",
    "            # the head of the verb should be the noun this thing refers to\n",
    "#             print(\"found relative clause, replacing\", noun, \"with\", noun.head.head)\n",
    "            noun = noun.head.head\n",
    "        if not noun._.in_coref:\n",
    "            spans.append(noun)\n",
    "        else:\n",
    "            for cluster in noun._.coref_clusters:\n",
    "                for span in cluster:\n",
    "                    if self.is_not_generic(span):\n",
    "                        spans.append(span)\n",
    "        return spans \n",
    "\n",
    "    def is_not_generic(self, span):\n",
    "        for word in span:\n",
    "            if word.pos_ != \"PRON\":\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(src, gen, debug=False):\n",
    "#     print(\"source:\", src_line[:100])\n",
    "#     print(\"summary:\", gen_line[:100])\n",
    "    src = nlp(src)\n",
    "    gen = nlp(gen)\n",
    "#     print(\"clusters:\", src._.coref_clusters)\n",
    "    kg = KnowledgeGraph()\n",
    "\n",
    "    # put all actors/acteds for each verb into knowledge graph\n",
    "    for ixt, token in enumerate(src):\n",
    "        if token.pos_ == \"VERB\":\n",
    "            kg.add_verb(token)\n",
    "    important_relations = []\n",
    "    contained = 0\n",
    "    missing = 0\n",
    "    contradiction = 0\n",
    "    total = 0\n",
    "    \n",
    "    for token in gen:\n",
    "        # ignore xcomp verbs \"tried TO EAT\" since will later be added to verb cluster\n",
    "        # still adds was/has/is/aux verbs though\n",
    "        if token.pos_ == \"VERB\" and not(token.dep_=='xcomp'):# or token.dep_=='ccomp'):\n",
    "            total += 1\n",
    "\n",
    "            relation = kg.get_relation(token)\n",
    "            r = kg.query_relation(relation)\n",
    "            if r[0] == kg.entailment:\n",
    "                contained += 1\n",
    "                important_relations.append(('contained', relation, r[1]))\n",
    "                if(debug):\n",
    "                    print(\"contained |\", relation, \"|\", r[1])\n",
    "            elif r[0] == kg.missing_dependencies:\n",
    "                missing += 1\n",
    "                important_relations.append(('missing', relation, r[1]))\n",
    "                if(debug):\n",
    "                    print(\"missing |\", relation, \"|\", r[1])\n",
    "            elif r[0] == kg.contradiction:\n",
    "                contradiction += 1\n",
    "                important_relations.append(('contradiction', relation, r[1]))\n",
    "                if(debug):\n",
    "                    print(\"contradiction |\", relation, \"|\", r[1])\n",
    "    \n",
    "    important_relations = sorted(important_relations)\n",
    "    colored_src, colored_gen = visualize([word.text for word in src], [word.text for word in gen], important_relations)\n",
    "    \n",
    "    if total == 0:\n",
    "        return important_relations, (0.0, 0.0, 0.0), (colored_src, colored_gen)\n",
    "    return important_relations, (100.0 * contained / total, \n",
    "                                 100.0 * missing / total, \n",
    "                                 100.0 * contradiction / total), (colored_src, colored_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(src0, gen0, important_relations):\n",
    "    colors = {'contained':lambda text: '\\033[0;32m' + text + '\\033[0m', \n",
    "              'missing':lambda text: '\\033[0;33m' + text + '\\033[0m', \n",
    "              'contradiction':lambda text: '\\033[0;31m' + text + '\\033[0m'}\n",
    "\n",
    "    colored_src = src0\n",
    "    colored_gen = gen0\n",
    "    for relation_tuple in important_relations:\n",
    "        result = relation_tuple[0]\n",
    "        relation = relation_tuple[1]\n",
    "        proof = relation_tuple[2]\n",
    "        \n",
    "        # color output doc\n",
    "        verbs = relation[0]\n",
    "        actors = relation[1]\n",
    "        acteds = relation[2]\n",
    "        for verb in verbs:\n",
    "            colored_gen[verb.i] = colors[result](verb.text)\n",
    "        for a in actors:\n",
    "            colored_gen[a.i] = colors[result](a.text)\n",
    "        for a in acteds:\n",
    "            colored_gen[a.i] = colors[result](a.text)\n",
    "            \n",
    "        # color source doc\n",
    "        for p in proof:\n",
    "            for verb in p[0][0]:\n",
    "                colored_src[verb.i] = colors[result](verb.text)\n",
    "            for a in p[0][1]:\n",
    "                colored_src[a.i] = colors[result](a.text)\n",
    "            for a in p[0][2]:\n",
    "                colored_src[a.i] = colors[result](a.text)\n",
    "\n",
    "    colored_src = ' '.join(colored_src)\n",
    "    colored_gen = ' '.join(colored_gen)\n",
    "\n",
    "    return colored_src, colored_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns average number of tokens copied = max copy length / unique phrases copied\n",
    "def avg_copy_length(src,gen):\n",
    "    src = src.split()\n",
    "    gen = gen.split()\n",
    "    substrings = {}\n",
    "    for ixgw,word in enumerate(gen):\n",
    "        substrings[ixgw] = []\n",
    "    \n",
    "    avg_length = 0\n",
    "    num_copied = 0\n",
    "    ixgw = 0\n",
    "    while(ixgw < len(gen)):\n",
    "        gen_word = gen[ixgw]\n",
    "        max_js = []\n",
    "        src_ixs = []\n",
    "        for ixsw, src_word in enumerate(src):\n",
    "            j = 0\n",
    "            while(ixgw+j <= len(gen) and ixsw+j <= len(src) and src[ixsw:ixsw+j] == gen[ixgw:ixgw+j]):\n",
    "                j += 1\n",
    "            if(len(max_js) == 0 or j > max_js[0]):\n",
    "                max_js = [j]\n",
    "                src_ixs = [ixsw]\n",
    "            elif(j == max_js[0]):\n",
    "                max_js.append(j)\n",
    "                src_ixs.append(ixsw)\n",
    "        substrings[ixgw] = ([gen[ixgw:ixgw+max_j-1] for max_j in max_js], src_ixs)\n",
    "        ixgw += 1\n",
    "        \n",
    "    for ixgw,gen_word in enumerate(gen):\n",
    "#         substr = substrings[ixgw][0]\n",
    "#         src_ix = substrings[ixgw][1]\n",
    "        contained = False\n",
    "        for src_ix in substrings[ixgw][1]:\n",
    "            if ixgw > 0 and src_ix-1 in substrings[ixgw-1][1]:\n",
    "                contained=True\n",
    "                break\n",
    "        \n",
    "        if not contained:\n",
    "            if(len(substrings[ixgw][0])>0):\n",
    "                num_copied += 1\n",
    "                print(substrings[ixgw])\n",
    "                print(len(substrings[ixgw][0][0]))\n",
    "                avg_length += len(substrings[ixgw][0][0])\n",
    "    avg_length /= num_copied\n",
    "    \n",
    "    return avg_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_copy_length(src_lines[6], gen_lines[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contained | ([claims], [rutherford], []) | [(([claims], [rutherford], []), ('verb similarity:', 1.0, 'contained dependences:', [(rutherford, rutherford, ('best match:', 1.0, (rutherford, rutherford)))]))]\n",
      "contained | ([were], [], []) | [(([were], [], []), ('verb similarity:', 1.0, 'contained dependences:', []))]\n",
      "missing | ([deported], [], [children]) | [(([deported], [], [children]), ('verb similarity:', 1.0, 'missing dependencies:', [children])), (([deported], [], [children]), ('verb similarity:', 1.0, 'missing dependencies:', [children])), (([deported], [], [giersch]), ('verb similarity:', 1.0, 'missing dependencies:', [children]))]\n",
      "contained | ([awarded], [court], [custody]) | [(([awarded], [court], [custody]), ('verb similarity:', 1.0, 'contained dependences:', [(court, court, ('best match:', 1.0, (court, court))), (custody, custody, ('best match:', 1.0, (custody, custody)))]))]\n",
      "contained | ([pleaded], [she], []) | [(([pleaded], [she], []), ('verb similarity:', 1.0, 'contained dependences:', [(she, she, ('best match:', 1.0, (her, her)))]))]\n",
      "contained | ([be], [], []) | [(([be], [], []), ('verb similarity:', 1.0, 'contained dependences:', []))]\n",
      "missing | ([reversed], [], [order]) | [(([reversed], [], [order]), ('verb similarity:', 1.0, 'missing dependencies:', [order]))]\n",
      "missing | ([said], [lawsuit], []) | []\n",
      "contained | ([has], [], []) | [(([has], [], []), ('verb similarity:', 1.0, 'contained dependences:', []))]\n",
      "contained | ([ordered, live], [court], [children]) | [(([ordered, live], [court], [children]), ('verb similarity:', 1.0, 'contained dependences:', [(court, court, ('best match:', 1.0, (court, court))), (children, children, ('best match:', 1.0, (children, children)))]))]\n",
      "contained | ([have], [they], [parent]) | [(([have], [they], [parent]), ('verb similarity:', 1.0, 'contained dependences:', [(they, they, ('best match:', 1.0, (children, children))), (parent, parent, ('best match:', 1.0, (parent, parent)))]))]\n",
      "contained | ([failed, argue], [rutherford], []) | [(([failed, argue], [rutherford], []), ('verb similarity:', 1.0, 'contained dependences:', [(rutherford, rutherford, ('best match:', 1.0, (rutherford, rutherford)))]))]\n",
      "contained | ([should], [], []) | [(([should], [], []), ('verb similarity:', 1.0, 'contained dependences:', []))]\n",
      "contained | ([intervene], [court], []) | [(([intervene], [court], []), ('verb similarity:', 1.0, 'contained dependences:', [(court, court, ('best match:', 1.0, (the federal court, the federal court)))]))]\n",
      "Src 6: a lawsuit filed by former gossip girl actress kelly rutherford attempting to have a judge order her kids to return to the u.s . from their father 's custody in france \u001b[0;32mhas\u001b[0m been dismissed once and for all . the case was dismissed with a court order stating that it did not have the jurisdiction to force the kids , son hermes , 8 , and daughter helena , 5 , to come back to the united states . \u001b[0;32mrutherford\u001b[0m , 46 , \u001b[0;32mclaims\u001b[0m her \u001b[0;33mchildren\u001b[0m \u001b[0;32mwere\u001b[0m illegally \u001b[0;33mdeported\u001b[0m to france when a california \u001b[0;32mcourt\u001b[0m \u001b[0;32mawarded\u001b[0m \u001b[0;32mcustody\u001b[0m to her ex - husband daniel giersch , 40 , and \u001b[0;32mshe\u001b[0m \u001b[0;32mpleaded\u001b[0m for the \u001b[0;33morder\u001b[0m to \u001b[0;32mbe\u001b[0m \u001b[0;33mreversed\u001b[0m . scroll down for video . kelly rutherford , pictured with her children , hermes and helena , during a party in the hamptons in august 2013 , was shut down by the courts again in a final plea to gain custody of her children . rutherford 's lawsuit stating that her \u001b[0;33mchildren\u001b[0m were illegally \u001b[0;33mdeported\u001b[0m from the united states was dismissed once and for all by a new york court . she claimed that no other u.s . \u001b[0;32mcourt\u001b[0m has \u001b[0;32mordered\u001b[0m \u001b[0;32mchildren\u001b[0m to \u001b[0;32mlive\u001b[0m in another country when \u001b[0;32mthey\u001b[0m \u001b[0;32mhave\u001b[0m an able \u001b[0;32mparent\u001b[0m in the united states . \u001b[0;33mgiersch\u001b[0m , who is a german citizen residing in france , was \u001b[0;33mdeported\u001b[0m from the u.s . over allegations of visa fraud . but the dismissal of her case states that \u001b[0;32mrutherford\u001b[0m \u001b[0;32mfailed\u001b[0m to \u001b[0;32margue\u001b[0m why the federal \u001b[0;32mcourt\u001b[0m \u001b[0;32mshould\u001b[0m \u001b[0;32mintervene\u001b[0m in her custody dispute with giersch . ` petitioners allege that the california state court 's custody order had the effect of deporting the children in violation of their fourteenth amendment right to remain in the united states , ' the document reads . the document added : ` there is no authority establishing the unconditional right of minor children to reside in the united states when one of their custodial parents lives abroad . ` likewise there is no ` ` plainly defined and peremptory duty ' ' requiring respondents to interfere with the custody order - nor is there , as petitioners contend , a general affirmative duty on federal agencies requiring them to intervene against what is claimed to be unconstitutional state action . ' after divorcing in 2010 , rutherford and ex - husband daniel giersch went through a nasty custody battle which ended with giersch being awarded custody\n",
      "Summary 6: kelly \u001b[0;32mrutherford\u001b[0m , 46 , \u001b[0;32mclaims\u001b[0m her \u001b[0;33mchildren\u001b[0m \u001b[0;32mwere\u001b[0m illegally \u001b[0;33mdeported\u001b[0m to france when a california \u001b[0;32mcourt\u001b[0m \u001b[0;32mawarded\u001b[0m \u001b[0;32mcustody\u001b[0m to her ex - husband daniel giersch , 40 , and \u001b[0;32mshe\u001b[0m \u001b[0;32mpleaded\u001b[0m for the \u001b[0;33morder\u001b[0m to \u001b[0;32mbe\u001b[0m \u001b[0;33mreversed\u001b[0m . rutherford 's \u001b[0;33mlawsuit\u001b[0m \u001b[0;33msaid\u001b[0m that no other u.s . \u001b[0;32mcourt\u001b[0m \u001b[0;32mhas\u001b[0m \u001b[0;32mordered\u001b[0m \u001b[0;32mchildren\u001b[0m to \u001b[0;32mlive\u001b[0m in another country when \u001b[0;32mthey\u001b[0m \u001b[0;32mhave\u001b[0m an able \u001b[0;32mparent\u001b[0m in the united states . \u001b[0;32mrutherford\u001b[0m \u001b[0;32mfailed\u001b[0m to \u001b[0;32margue\u001b[0m why the federal \u001b[0;32mcourt\u001b[0m \u001b[0;32mshould\u001b[0m \u001b[0;32mintervene\u001b[0m in her custody dispute with giersch .\n",
      "Score: (78.57142857142857, 21.428571428571427, 0.0)\n",
      "([['kelly', 'rutherford', ',']], [118])\n",
      "3\n",
      "([['rutherford', ',', '46', ',', 'claims', 'her', 'children', 'were', 'illegally', 'deported', 'to', 'france', 'when', 'a', 'california', 'court', 'awarded', 'custody', 'to', 'her', 'ex-husband', 'daniel', 'giersch', ',', '40', ',', 'and', 'she', 'pleaded', 'for', 'the', 'order', 'to', 'be', 'reversed', '.']], [77])\n",
      "36\n",
      "([['.', \"rutherford's\", 'lawsuit']], [157])\n",
      "3\n",
      "([['the', 'united', 'states', '.', 'rutherford']], [73])\n",
      "5\n",
      "([['rutherford', 'failed', 'to', 'argue', 'why', 'the', 'federal', 'court', 'should', 'intervene', 'in', 'her', 'custody', 'dispute', 'with', 'giersch', '.']], [239])\n",
      "17\n",
      "Avg copy length: 12.8\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "line_num = 0\n",
    "scores = []\n",
    "src_lines = []\n",
    "gen_lines = []\n",
    "with open(\"data/test.txt.src.tagged.shuf.400words\") as src:\n",
    "    with open(\"data/bottom_up_cnndm_015_threshold.out\") as gen:\n",
    "        for i, (src_line, gen_line) in enumerate(zip(src, gen)):\n",
    "            if i <=5:\n",
    "                continue\n",
    "            if line_num > 0 and not i == line_num:\n",
    "                continue\n",
    "            if line_num == 0 and i >= 7:\n",
    "                break\n",
    "            src_line = clean_src(src_line)\n",
    "            src_lines.append(src_line)\n",
    "            gen_line = clean_gen(gen_line)\n",
    "            gen_lines.append(gen_line)\n",
    "            important_relations, score, (colored_src, colored_gen) = test(src_line, gen_line, debug=True)\n",
    "            print(f\"Src {i}:\"%{i:i}, colored_src)\n",
    "            print(f\"Summary {i}:\"%{i:i}, colored_gen)\n",
    "            print(\"Score:\", score)\n",
    "            avg_length = avg_copy_length(src_line, gen_line)\n",
    "            print(\"Avg copy length:\", avg_length)\n",
    "            print(\"===========================================================================================\")\n",
    "            scores.append(score)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(gen_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kelly advmod ADV rutherford\n",
      "rutherford nsubj NOUN claims\n",
      ", punct PUNCT rutherford\n",
      "46 appos NUM rutherford\n",
      ", punct PUNCT rutherford\n",
      "claims ROOT VERB claims\n",
      "her poss DET children\n",
      "children nsubjpass NOUN deported\n",
      "were auxpass VERB deported\n",
      "illegally advmod ADV deported\n",
      "deported ccomp VERB claims\n",
      "to prep ADP deported\n",
      "france pobj NOUN to\n",
      "when advmod ADV awarded\n",
      "a det DET court\n",
      "california compound ADJ court\n",
      "court nsubj NOUN awarded\n",
      "awarded advcl VERB deported\n",
      "custody dobj NOUN awarded\n",
      "to dative ADP awarded\n",
      "her poss DET giersch\n",
      "ex subtok ADJ -\n",
      "- subtok NOUN husband\n",
      "husband amod NOUN giersch\n",
      "daniel compound NOUN giersch\n",
      "giersch pobj NOUN to\n",
      ", punct PUNCT giersch\n",
      "40 appos NUM giersch\n",
      ", punct PUNCT claims\n",
      "and cc CCONJ claims\n",
      "she nsubj PRON pleaded\n",
      "pleaded conj VERB claims\n",
      "for mark ADP reversed\n",
      "the det DET order\n",
      "order nsubjpass NOUN reversed\n",
      "to aux PART reversed\n",
      "be auxpass VERB reversed\n",
      "reversed advcl VERB pleaded\n",
      ". punct PUNCT pleaded\n",
      "rutherford poss NOUN lawsuit\n",
      "'s case PART rutherford\n",
      "lawsuit nsubj NOUN said\n",
      "said ROOT VERB said\n",
      "that punct ADP said\n",
      "no punct DET said\n",
      "other pobj ADJ no\n",
      "u.s punct PROPN .\n",
      ". pobj PUNCT no\n",
      "court nsubj NOUN ordered\n",
      "has aux VERB ordered\n",
      "ordered ROOT VERB ordered\n",
      "children dobj NOUN ordered\n",
      "to aux PART live\n",
      "live xcomp VERB ordered\n",
      "in prep ADP live\n",
      "another det DET country\n",
      "country pobj NOUN in\n",
      "when advmod ADV have\n",
      "they nsubj PRON have\n",
      "have advcl VERB live\n",
      "an det DET parent\n",
      "able amod ADJ parent\n",
      "parent dobj NOUN have\n",
      "in prep ADP parent\n",
      "the det DET states\n",
      "united amod ADJ states\n",
      "states pobj NOUN in\n",
      ". punct PUNCT ordered\n",
      "rutherford nsubj NOUN failed\n",
      "failed ROOT VERB failed\n",
      "to aux PART argue\n",
      "argue xcomp VERB failed\n",
      "why advmod ADV intervene\n",
      "the det DET court\n",
      "federal amod ADJ court\n",
      "court nsubj NOUN intervene\n",
      "should aux VERB intervene\n",
      "intervene ccomp VERB argue\n",
      "in prep ADP intervene\n",
      "her poss DET dispute\n",
      "custody compound NOUN dispute\n",
      "dispute pobj NOUN in\n",
      "with prep ADP intervene\n",
      "giersch pobj NOUN with\n",
      ". punct PUNCT failed\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.dep_, token.pos_, token.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_lines[0].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.load(\"sandbox/scores.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(scores[:,0], scores[:,2], marker='.')\n",
    "plt.xlabel(\"% contained\")\n",
    "plt.ylabel(\"% contradiction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying BERT embeddings...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relations between iran and saudi arabia have always been thorny , but rarely has the state of affairs been as venomous as it is today',\n",
       " 'tehran and riyadh each point to the other as the main reason for much of the turmoil in the middle east',\n",
       " 'in its most recent incarnation , the iranian-saudi conflict by proxy has reached yemen in a spiral that both sides portray as climatic',\n",
       " \"for riyadh and its regional allies , the saudi military intervention in yemen -- `` operation decisive storm'' -- is the moment the sunni arab nation finally woke up to repel the expansion of shia-iranian influence\",\n",
       " \"for tehran and its regional allies -- including the houthi movement in yemen -- saudi arabia's actions are in defense of a retrogressive status quo order that is no longer tenable\",\n",
       " 'and yet both sides have good reasons to want to stop the yemeni crisis from spiraling out of control and evolving into an unwinnable war',\n",
       " 'when iranian president hassan rouhani was elected in june 2013 , he pledged to reach out to riyadh',\n",
       " \"he was up front and called tehran's steep deterioration of relations with the saudis over the last decade as one of the principal burdens on iranian foreign policy\",\n",
       " 'from lebanon and afghanistan to pakistan and the gaza strip , the iranian-saudi rivalry and conflict through proxy has been deep and costly',\n",
       " \"and yet despite rouhani's open pledge , profound differences over syria and iraq in particular have kept riyadh and tehran apart\",\n",
       " 'but if the questions of syria and iraq prevented a pause in hostilities , the saudi military intervention in yemen since late march has all but raised the stakes to unprecedentedly dangerous levels',\n",
       " 'unlike in syria and in iraq , the saudi military is now directly battling it out with iranian-backed rebels in yemen',\n",
       " \"while riyadh no doubt exaggerates tehran's role in the yemen crisis , its fingerprints are nonetheless evident\",\n",
       " \"`` iran provides financial support , weapons , training and intelligence to houthis ,'' gerald feierstein , a u.s. state department official and former yemen ambassador , told a congressional hearing last week\",\n",
       " '`` we believe that iran sees opportunities with the houthis to expand its influence in yemen and threaten saudi and gulf arab']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embedding = BertEmbedding()\n",
    "embed = bert_embedding(src_lines[0].split(' . '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relations',\n",
       " 'between',\n",
       " 'iran',\n",
       " 'and',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'have',\n",
       " 'always',\n",
       " 'been',\n",
       " 'thorny',\n",
       " ',',\n",
       " 'but',\n",
       " 'rarely',\n",
       " 'has',\n",
       " 'the',\n",
       " 'state',\n",
       " 'of',\n",
       " 'affairs',\n",
       " 'been',\n",
       " 'as',\n",
       " 'venomous']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(embed[0][1])):\n",
    "#     plt.scatter([embed[0][1][i][0]], [embed[0][1][i][1]], label=embed[0][0][i])\n",
    "# # plt.scatter([embed[0][1][i][0] for i in range(len(embed[0][1]))], \n",
    "# #             [embed[0][1][i][1] for i in range(len(embed[0][1]))])\n",
    "# # plt.scatter([embed[0][1][2][0]], [embed[0][1][2][1]])\n",
    "# # plt.scatter([embed[0][1][4][0]], [embed[0][1][4][1]])\n",
    "# # plt.scatter([embed[0][1][5][0]], [embed[0][1][5][1]])\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.376158"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(embed[0][1][4] - embed[0][1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab file is not found. Downloading.\n",
      "Downloading /Users/cliang/.mxnet/models/book_corpus_wiki_en_uncased-a6607397.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/book_corpus_wiki_en_uncased-a6607397.zip...\n",
      "Downloading /Users/cliang/.mxnet/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip...\n"
     ]
    }
   ],
   "source": [
    "bert_embedding = BertEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "with open(\"data/test.txt.src.tagged.shuf.400words\") as src:\n",
    "    with open(\"data/bottom_up_cnndm_015_threshold.out\") as gen:\n",
    "        for src_line0, gen_line0 in zip(src, gen):\n",
    "            if(i >= 8):\n",
    "                break\n",
    "#             print(src_line0)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = gen_line.split(' . ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bert_embedding([\"I ate a dog\", \"I ate a cat\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'ate', 'a', 'dog']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3448873"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(result[1][1][3]- result[0][1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9955516"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(result[1][1][1]- result[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
