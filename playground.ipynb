{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sandbox.celine_knowledge_graph import *\n",
    "# from sandbox.spacy_experiments import *\n",
    "# from sandbox.neuralcoref_experiments import *\n",
    "# from bert_embedding import BertEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1149666d8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import spacy\n",
    "import neuralcoref\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_src(s):\n",
    "    s = s.split()\n",
    "    # remove everything from \"-lrb-\" to \"-rrb-\"\n",
    "    s2 = []\n",
    "    in_paren = False\n",
    "    for ixw, w in enumerate(s):\n",
    "        if(w==\"-lrb-\"):\n",
    "            in_paren=True\n",
    "        elif(w=='-rrb-'):\n",
    "            in_paren=False\n",
    "        elif(w==\"-lsb-\" or w==\"-rsb-\"):\n",
    "            continue\n",
    "        elif(len(w) > 1 and w[0] == '\\''):\n",
    "            s2[-1] = s2[-1]+w\n",
    "        elif not in_paren and not (w == '<t>' or w == '</t>'):\n",
    "            s2.append(w)\n",
    "    return ' '.join(s2)\n",
    "\n",
    "def clean_gen(s):\n",
    "    s = s.split()\n",
    "    # remove everything from \"-lrb-\" to \"-rrb-\"\n",
    "    s2 = []\n",
    "    in_paren = False\n",
    "    for w in s:\n",
    "        if(w==\"-lrb-\"):\n",
    "            in_paren=True\n",
    "        elif(w=='-rrb-'):\n",
    "            in_paren=False\n",
    "        elif(w==\"-lsb-\" or w==\"-rsb-\"):\n",
    "            continue\n",
    "        elif(len(w) > 1 and w[0] == '\\''):\n",
    "            s2[-1] = s2[-1]+w\n",
    "        elif not in_paren and not(w == '<t>' or w == '</t>'):\n",
    "            s2.append(w)\n",
    "    return ' '.join(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeGraph:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.relations = list()\n",
    "        self.noun_threshold = 0.9\n",
    "        self.verb_threshold = 0.9\n",
    "        self.weak_threshold = 0.5\n",
    "        self.entailment = 0\n",
    "        self.entailment_dissimilar_verbs = 0.5\n",
    "        self.dissimilar_verbs = 1\n",
    "        self.missing_dependencies = 2\n",
    "        self.contradiction = 3\n",
    "\n",
    "    # ==========================================\n",
    "    # 1) adding to KnowledgeGraph relations \n",
    "    # ==========================================\n",
    "    def add_verb(self, verb):\n",
    "        self.relations.append(self.get_relation(verb))\n",
    "        \n",
    "    ##### extracting relations from sentence #####\n",
    "    def get_relation(self, verb):\n",
    "        # get all equivalent verbs\n",
    "        verb_cluster = self.get_verb_cluster(verb)\n",
    "        actors = []\n",
    "        acteds = []\n",
    "        \n",
    "        # get all actors/acteds of verbs in equivalencies\n",
    "        for verb in verb_cluster:\n",
    "            actors += self.get_actors(verb)\n",
    "            acteds += self.get_acteds(verb)\n",
    "        return verb_cluster, actors, acteds\n",
    "    \n",
    "    # =========================================\n",
    "    # 2) looks through verb's children for\n",
    "    # verb equivalencies (xcomp)\n",
    "    # =========================================\n",
    "    def get_verb_cluster(self, verb):\n",
    "        verb_cluster = [verb]\n",
    "        for child in verb.children:\n",
    "            if child.dep_ == \"xcomp\":# or child.dep_ == \"ccomp\":\n",
    "                verb_cluster.append(child)\n",
    "        return verb_cluster\n",
    "        \n",
    "    def get_actors(self, verb):\n",
    "        actors = []\n",
    "        for child in verb.children:\n",
    "            # child is a nominative subject\n",
    "            if child.dep_ == \"nsubj\":\n",
    "                actors.append(child)\n",
    "            # child is something like \"by\"\n",
    "            elif child.dep_ == \"agent\":  \n",
    "                # passive, look for true actor\n",
    "                for grandchild in child.children:\n",
    "                    if grandchild.dep_ == \"pobj\":\n",
    "                        actors.append(grandchild)\n",
    "        return actors\n",
    "\n",
    "    def get_acteds(self, verb):\n",
    "        acteds = []\n",
    "        for child in verb.children:\n",
    "            #child is direct object or passive subject\n",
    "            if child.dep_ == \"dobj\" or child.dep_ == \"nsubjpass\":\n",
    "                acteds.append(child)\n",
    "        return acteds\n",
    "\n",
    "    # =========================================\n",
    "    # 3) checking hypothesis relation against \n",
    "    # premise's KnowledgeGraph relations\n",
    "    # =========================================\n",
    "    def query_relation(self, hypothesis):\n",
    "        missing_dependencies = []\n",
    "        contradiction = []\n",
    "        for premise in self.relations:\n",
    "            r = self.implied_relation(premise, hypothesis)\n",
    "\n",
    "            # once we find that hypothesis is contained, accept this relation as verified\n",
    "            # if the verb similarity is too low, we make note of this but still mark it as entailed\n",
    "            if r[0] == self.entailment:\n",
    "                return r[0], [(premise,r[1])]\n",
    "            elif r[0] == self.missing_dependencies:\n",
    "                missing_dependencies.append((premise, r[1]))\n",
    "            elif r[0] == self.contradiction:\n",
    "                contradiction.append((premise, r[1]))\n",
    "        if len(contradiction) > 0:\n",
    "            return self.contradiction, contradiction\n",
    "        return self.missing_dependencies, missing_dependencies\n",
    "    \n",
    "    # check if a hypothesis is verified by a premise \n",
    "    # returns (result, proof)\n",
    "    def implied_relation(self, premise, hypothesis):\n",
    "        # premise[0] and hypothesis[0] is a list (verb cluster)\n",
    "        verb_similarity, best_pair = self.verb_same(premise[0], hypothesis[0])\n",
    "        if verb_similarity < self.verb_threshold:\n",
    "            return self.dissimilar_verbs, hypothesis\n",
    "        \n",
    "        # check setminus of premise \\ hypothesis\n",
    "        actor_actor = self.noun_intersect_setminus(premise[1], hypothesis[1])\n",
    "        acted_acted = self.noun_intersect_setminus(premise[2], hypothesis[2])\n",
    "        actor_acted = self.noun_intersect_setminus(premise[1], hypothesis[2])\n",
    "        acted_actor = self.noun_intersect_setminus(premise[2], hypothesis[1])\n",
    "\n",
    "        contained_deps = actor_actor[0] + acted_acted[0]\n",
    "        missing_deps = actor_actor[1] + acted_acted[1]\n",
    "        contradiction_deps = actor_acted[0] + acted_actor[0]\n",
    "        \n",
    "        if len(missing_deps) == 0:\n",
    "            return self.entailment, (\"verb similarity:\", verb_similarity,\n",
    "                    \"contained dependences:\", contained_deps)\n",
    "        if len(contradiction_deps) > 0:\n",
    "            return self.contradiction, (\"verb similarity:\", verb_similarity,\n",
    "                    \"contradictory dependences:\", contradiction_deps)\n",
    "        return self.missing_dependencies, (\"verb similarity:\",\n",
    "                verb_similarity, \"missing dependencies:\", missing_deps)\n",
    "\n",
    "    \n",
    "    # ========================\n",
    "    # verb helper functions\n",
    "    # ========================\n",
    "    # v1 comes from premise/source, v2 comes from hypothesis/output\n",
    "    def verb_same(self, v1_cluster, v2_cluster):\n",
    "        maximum_similarity = 0\n",
    "        maximum_pair = None\n",
    "        for v1 in v1_cluster:\n",
    "            for v2 in v2_cluster:\n",
    "                similarity = v1.similarity(v2)\n",
    "                if(similarity > maximum_similarity):\n",
    "                    maximum_similarity = similarity\n",
    "                    maximum_pair = v1, v2\n",
    "        return maximum_similarity, maximum_pair\n",
    "    \n",
    "\n",
    "    # ========================\n",
    "    # noun helper functions\n",
    "    # ========================\n",
    "    def noun_intersect_setminus(self, supset, subset):\n",
    "        contained_nouns = []\n",
    "        missing_nouns = []\n",
    "        for n in subset:\n",
    "            contained = False\n",
    "            for n2 in supset:\n",
    "                r = self.noun_same(n, n2)\n",
    "                if verbose:\n",
    "                    print(n, n2, r)\n",
    "                if r[0]:\n",
    "                    contained = True\n",
    "                    contained_nouns.append((n, n2, r[1]))\n",
    "                    continue\n",
    "            if not contained:\n",
    "                missing_nouns.append(n)\n",
    "        return contained_nouns, missing_nouns\n",
    "\n",
    "    def noun_same(self, n1, n2):\n",
    "        tokens1 = self.get_valid_cluster_tokens(n1)\n",
    "        tokens2 = self.get_valid_cluster_tokens(n2)\n",
    "        if len(tokens1) == 0 or len(tokens2) == 0:\n",
    "            tokens1 = self.get_valid_cluster_tokens(n1, True)\n",
    "            tokens2 = self.get_valid_cluster_tokens(n2, True)\n",
    "        maximum_similarity = 0\n",
    "        maximum_pair = None\n",
    "        for token1 in tokens1:\n",
    "            for token2 in tokens2:\n",
    "                token_similarity = token1.similarity(token2)\n",
    "                if token_similarity > maximum_similarity:\n",
    "                    maximum_similarity = token_similarity\n",
    "                    maximum_pair = token1, token2\n",
    "        if maximum_similarity > self.noun_threshold:\n",
    "            return True, (\"best match:\", maximum_similarity, maximum_pair)\n",
    "        return False, (\"best match:\", maximum_similarity, maximum_pair)\n",
    "    \n",
    "    def get_valid_cluster_tokens(self, noun, use_generic=False):\n",
    "        tokens = list()\n",
    "        if (noun.pos_ == 'PRON' or noun.pos_ == 'DET') and noun.head.dep_ == 'relcl':\n",
    "            # the head is the verb of the relative clause\n",
    "            # the head of the verb should be the noun this thing refers to\n",
    "            if verbose:\n",
    "                print(\"found relative clause, replacing\", noun, \"with\", noun.head.head)\n",
    "            noun = noun.head.head\n",
    "        for cluster in noun._.coref_clusters:\n",
    "            for span in cluster:\n",
    "                for token in span:\n",
    "                    if use_generic or not self.is_generic(token):\n",
    "                        if verbose and self.is_generic(token):\n",
    "                            print(colored(\"warning:\", \"yellow\"), \"using generic token\", noun)\n",
    "                        tokens.append(token)\n",
    "        if len(tokens) == 0:\n",
    "            if use_generic or not self.is_generic(noun):\n",
    "                if verbose and self.is_generic(noun):\n",
    "                    print(colored(\"warning:\", \"yellow\"), \"using generic token\", noun)\n",
    "                tokens.append(noun)\n",
    "        return tokens \n",
    "\n",
    "    def is_generic(self, token):\n",
    "        return token.pos_ == \"PRON\" or token.pos_ == \"DET\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(src, gen):\n",
    "#     print(\"source:\", src_line[:100])\n",
    "#     print(\"summary:\", gen_line[:100])\n",
    "    src = nlp(src)\n",
    "    gen = nlp(gen)\n",
    "#     print(\"clusters:\", src._.coref_clusters)\n",
    "    kg = KnowledgeGraph()\n",
    "\n",
    "    # put all actors/acteds for each verb into knowledge graph\n",
    "    for ixt, token in enumerate(src):\n",
    "        if token.pos_ == \"VERB\":\n",
    "            kg.add_verb(token)\n",
    "    important_relations = []\n",
    "    contained = 0\n",
    "    missing = 0\n",
    "    contradiction = 0\n",
    "    total = 0\n",
    "    \n",
    "    for token in gen:\n",
    "        # ignore xcomp verbs \"tried TO EAT\" since will later be added to verb cluster\n",
    "        # still adds was/has/is/aux verbs though\n",
    "        if token.pos_ == \"VERB\" and not(token.dep_=='xcomp'):# or token.dep_=='ccomp'):\n",
    "            relation = kg.get_relation(token)\n",
    "            # skip those relations with no actors/acteds\n",
    "            if (len(relation[1]) + len(relation[2]) == 0):\n",
    "                continue\n",
    "            \n",
    "            total += 1\n",
    "            r = kg.query_relation(relation)\n",
    "            if r[0] == kg.entailment:\n",
    "                contained += 1\n",
    "                important_relations.append(('contained', relation, r[1]))\n",
    "                if(verbose):\n",
    "                    print(\"contained |\", relation, \"|\", r[1])\n",
    "#             elif r[0] == kg.entailment_dissimilar_verbs:\n",
    "#                 missing += 1\n",
    "#                 important_relations.append(('contained-noverb', relation, r[1]))\n",
    "#                 if(verbose):\n",
    "#                     print(\"contained-noverb |\", relation, \"|\", r[1])\n",
    "            elif r[0] == kg.missing_dependencies:\n",
    "                missing += 1\n",
    "                important_relations.append(('missing', relation, r[1]))\n",
    "                if(verbose):\n",
    "                    print(colored(\"missing\", \"yellow\"), \"|\", relation, \"|\", r[1])\n",
    "            elif r[0] == kg.contradiction:\n",
    "                contradiction += 1\n",
    "                important_relations.append(('contradiction', relation, r[1]))\n",
    "                if(verbose):\n",
    "                    print(colored(\"contradiction\", \"red\"), \"|\", relation, \"|\", r[1])\n",
    "    \n",
    "    important_relations = sorted(important_relations)\n",
    "    colored_src, colored_gen = visualize([word.text for word in src], [word.text for word in gen], important_relations)\n",
    "    \n",
    "    if total == 0:\n",
    "        return important_relations, (0.0, 0.0, 0.0), (colored_src, colored_gen)\n",
    "    return important_relations, (100.0 * contained / total, \n",
    "                                 100.0 * missing / total, \n",
    "                                 100.0 * contradiction / total), (colored_src, colored_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(src0, gen0, important_relations):\n",
    "    colors = {'contained':lambda text: '\\033[0;32m' + text + '\\033[0m', \n",
    "#               'contained-noverb':lambda text: '\\033[0;95m' + text + '\\033[0m', \n",
    "              'missing':lambda text: '\\033[0;33m' + text + '\\033[0m', \n",
    "              'contradiction':lambda text: '\\033[0;31m' + text + '\\033[0m'}\n",
    "\n",
    "    colored_src = src0\n",
    "    colored_gen = gen0\n",
    "    for order in ['missing', 'contained-noverb', 'contained', 'contradiction']:\n",
    "        for relation_tuple in important_relations:\n",
    "            result = relation_tuple[0]\n",
    "            relation = relation_tuple[1]\n",
    "            proof = relation_tuple[2]\n",
    "            if not(result == order):\n",
    "                continue\n",
    "            # color output doc\n",
    "            verbs = relation[0]\n",
    "            actors = relation[1]\n",
    "            acteds = relation[2]\n",
    "            for verb in verbs:\n",
    "                colored_gen[verb.i] = colors[result](verb.text)\n",
    "            for a in actors:\n",
    "                colored_gen[a.i] = colors[result](a.text)\n",
    "            for a in acteds:\n",
    "                colored_gen[a.i] = colors[result](a.text)\n",
    "\n",
    "            # color source doc\n",
    "            for p in proof:\n",
    "                for verb in p[0][0]:\n",
    "                    colored_src[verb.i] = colors[result](verb.text)\n",
    "                for a in p[0][1]:\n",
    "                    colored_src[a.i] = colors[result](a.text)\n",
    "                for a in p[0][2]:\n",
    "                    colored_src[a.i] = colors[result](a.text)\n",
    "\n",
    "    colored_src = ' '.join(colored_src)\n",
    "    colored_gen = ' '.join(colored_gen)\n",
    "\n",
    "    return colored_src, colored_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns average number of tokens copied = max copy length / unique phrases copied\n",
    "def avg_copy_length(src,gen):\n",
    "    src = src.split()\n",
    "    gen = gen.split()\n",
    "    substrings = {}\n",
    "    for ixgw,word in enumerate(gen):\n",
    "        substrings[ixgw] = []\n",
    "    \n",
    "    avg_length = 0\n",
    "    num_copied = 0\n",
    "    ixgw = 0\n",
    "    while(ixgw < len(gen)):\n",
    "        gen_word = gen[ixgw]\n",
    "        max_js = []\n",
    "        src_ixs = []\n",
    "        for ixsw, src_word in enumerate(src):\n",
    "            j = 0\n",
    "            while(ixgw+j <= len(gen) and ixsw+j <= len(src) and src[ixsw:ixsw+j] == gen[ixgw:ixgw+j]):\n",
    "                j += 1\n",
    "            if(len(max_js) == 0 or j > max_js[0]):\n",
    "                max_js = [j]\n",
    "                src_ixs = [ixsw]\n",
    "            elif(j == max_js[0]):\n",
    "                max_js.append(j)\n",
    "                src_ixs.append(ixsw)\n",
    "        substrings[ixgw] = ([gen[ixgw:ixgw+max_j-1] for max_j in max_js], src_ixs)\n",
    "        ixgw += 1\n",
    "        \n",
    "    for ixgw,gen_word in enumerate(gen):\n",
    "#         substr = substrings[ixgw][0]\n",
    "#         src_ix = substrings[ixgw][1]\n",
    "        contained = False\n",
    "        for src_ix in substrings[ixgw][1]:\n",
    "            if ixgw > 0 and src_ix-1 in substrings[ixgw-1][1]:\n",
    "                contained=True\n",
    "                break\n",
    "        \n",
    "        if not contained:\n",
    "            if(len(substrings[ixgw][0])>0):\n",
    "                num_copied += 1\n",
    "#                 print(substrings[ixgw])\n",
    "#                 print(len(substrings[ixgw][0][0]))\n",
    "                avg_length += len(substrings[ixgw][0][0])\n",
    "    \n",
    "    avg_length = 0 if num_copied = 0 else avg_length/num_copied\n",
    "    \n",
    "    return avg_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================\n",
      "Src 0: marseille \u001b[0;32mprosecutor\u001b[0m \u001b[0;32msays\u001b[0m ` ` so far no \u001b[0;32mvideos\u001b[0m were \u001b[0;32mused\u001b[0m in the crash investigation ' ' despite media reports . journalists at bild and paris match are ` ` very confident ' ' the video clip is real , an editor says . andreas lubitz had informed his lufthansa training school of an episode of severe depression , airline says . marseille , france ( cnn ) the french prosecutor leading an investigation into the crash of germanwings flight 9525 insisted wednesday that \u001b[0;33mhe\u001b[0m \u001b[0;33mwas\u001b[0m not aware of any video footage from on board the plane . marseille prosecutor brice robin told cnn that ` ` so far no videos were used in the crash investigation . ' ' he added , ` ` a person \u001b[0;32mwho\u001b[0m \u001b[0;32mhas\u001b[0m such a video \u001b[0;32mneeds\u001b[0m to immediately \u001b[0;31mgive\u001b[0m \u001b[0;31mit\u001b[0m to the investigators . ' ' robin 's \u001b[0;32mcomments\u001b[0m \u001b[0;32mfollow\u001b[0m \u001b[0;32mclaims\u001b[0m by two magazines , german daily bild and french paris match , of a cell phone video showing the harrowing final seconds from on board germanwings flight 9525 as it crashed into the french alps . all 150 on board were killed . paris match and bild reported that the \u001b[0;32mvideo\u001b[0m \u001b[0;33mwas\u001b[0m \u001b[0;32mrecovered\u001b[0m from a phone at the wreckage site . the two publications described the supposed video , but did not post it on their websites . the publications said that they watched the video , which \u001b[0;33mwas\u001b[0m found by a source close to the investigation . ` ` one can hear cries of ' my god ' in several languages , '' paris match reported . ` ` metallic banging can also be heard more than three times , perhaps of the pilot trying to open the cockpit door with a heavy object . towards the end , after a heavy shake , stronger than the others , the screaming intensifies . then nothing . ' ' ` ` it is a very disturbing scene , '' said julian reichelt , editor - in - chief of bild online . an official with france 's accident investigation agency , the bea , said the agency is not aware of any such video . lt . col . jean - marc menichini , a french gendarmerie spokesman in charge of communications on rescue efforts around the germanwings crash site , told cnn that the reports were ` ` completely wrong ' ' and ` ` unwarranted . ' ' cell phones have been collected at the site , he said , but that they ` ` had n't been exploited yet . ' ' menichini said he believed the cell phones would need to be sent to the criminal research institute in rosny sous - bois , near paris , in order to be analyzed by specialized technicians working hand - in - hand with investigators . but none of the cell phones found so far have been sent to the institute , menichini said . asked whether staff involved in the search could have leaked a memory card to the media , menichini answered with a categorical ` ` no . ' ' reichelt told ` ` erin burnett : outfront ' ' that he had watched the video and stood by the report , saying bild and paris match are ` ` very confident ' ' that the clip is real . he noted that investigators only revealed they 'd recovered cell phones from the crash site after bild and paris match published their reports . ` ` that is something we did not know before . ... overall we can say many things of the investigation were n't revealed by the investigation at the beginning , '' he said . \u001b[0;33mwhat\u001b[0m \u001b[0;33mwas\u001b[0m mental state of germanwings co - pilot ? german airline lufthansa confirmed tuesday that co - pilot andreas lubitz had battled depression years before he took the controls of germanwings flight 9525 , which he 's accused of deliberately crashing last week in the french alps . lubitz told his lufthansa flight training school in 2009 that he had a ` ` previous episode of severe depression , '' the airline said tuesday . email correspondence between lubitz and the school discovered in an internal investigation , lufthansa said , included medical documents he submitted in connection with resuming his flight training . the announcement indicates that lufthansa , the parent company of germanwings , knew of lubitz 's battle with depression , allowed him to continue training and ultimately put him in the cockpit . lufthansa , whose ceo carsten spohr previously said lubitz \u001b[0;33mwas\u001b[0m 100 % fit to fly , described its statement tuesday as a ` ` swift and seamless clarification ' ' and said it \u001b[0;33mwas\u001b[0m sharing the information and documents -- including training and medical records -- with public prosecutors . spohr traveled to the crash site wednesday , where recovery teams have been working for the past week to recover human remains and plane debris scattered across a steep mountainside . he saw the crisis center set up in seyne - les - alpes , laid a wreath in the village of le vernet , closer to the crash site , where grieving families have left flowers at a simple stone memorial . menichini told cnn late tuesday that no visible human remains were left at the site but recovery teams would keep searching . french president francois hollande , speaking tuesday , said that it should be possible to identify all the victims using dna analysis by the end of the week , sooner than authorities had previously suggested . in the meantime , the recovery of the victims ' personal belongings will start wednesday , menichini said . among those personal belongings could be more cell phones belonging to the 144 passengers and six crew on board . check out the latest from our correspondents . the details about lubitz 's correspondence with the flight school during his training were among several developments as investigators continued to delve into what caused the crash and lubitz 's possible motive for downing the jet . a lufthansa spokesperson told cnn on tuesday that lubitz had a valid medical certificate , had passed all his examinations and ` ` held all the licenses required . ' ' earlier , a spokesman for the prosecutor 's office in dusseldorf , christoph kumpa , said medical records reveal lubitz suffered from suicidal tendencies at some point before his aviation career and underwent psychotherapy before he got his pilot 's license . kumpa emphasized there 's no evidence suggesting lubitz \u001b[0;33mwas\u001b[0m suicidal or acting aggressively before the crash . investigators are looking into whether lubitz feared his medical condition would cause him to lose his pilot 's license , a european government official briefed on the investigation told cnn on tuesday . while flying \u001b[0;33mwas\u001b[0m ` ` a big part of his life , '' the source said , it 's only one theory being considered . another source , a law enforcement official briefed on the investigation , also told cnn that authorities believe the primary \u001b[0;33mmotive\u001b[0m for lubitz to bring down the plane \u001b[0;33mwas\u001b[0m that he feared he would not be allowed to fly because of his medical problems . lubitz 's girlfriend told investigators he had seen an eye doctor and a neuropsychologist , both of whom deemed him unfit to work recently and concluded he had psychological issues , the european government official said . but no matter what details emerge about his previous mental health struggles , there 's more to the story , said brian russell , a forensic psychologist . ` ` psychology can explain why somebody would turn rage inward on themselves about the fact that maybe they were n't going to keep doing their job and they 're upset about that and so they 're suicidal , '' he said . ` ` but there is no mental illness that explains why somebody then feels entitled to also take that rage and turn it outward on 149 other people who had nothing to do with the person 's problems . ' ' germanwings crash compensation : what we know . \u001b[0;33mwho\u001b[0m \u001b[0;33mwas\u001b[0m the captain of germanwings flight 9525 ? cnn 's margot haddad reported from marseille and pamela brown from dusseldorf , while laura smith - spark wrote from london . cnn 's frederik pleitgen , pamela boykoff , antonia mortensen , sandrine amiel and anna - maja rappard contributed to this report .\n",
      "===========================================================================================\n",
      "Summary 0: french \u001b[0;32mprosecutor\u001b[0m \u001b[0;32msays\u001b[0m \u001b[0;33mhe\u001b[0m \u001b[0;33mwas\u001b[0m not aware of any video footage . robin 's \u001b[0;32mcomments\u001b[0m \u001b[0;32mfollow\u001b[0m \u001b[0;32mclaims\u001b[0m by two magazines , daily bild and french paris match . the \u001b[0;32mvideo\u001b[0m was \u001b[0;32mrecovered\u001b[0m from a phone at the wreckage site . marseille prosecutor brice \u001b[0;32mrobin\u001b[0m \u001b[0;32msays\u001b[0m ` ` no \u001b[0;32mvideos\u001b[0m were \u001b[0;32mused\u001b[0m in the crash investigation ' ' new : ` ` a \u001b[0;31mperson\u001b[0m \u001b[0;32mwho\u001b[0m \u001b[0;32mhas\u001b[0m such a video \u001b[0;32mneeds\u001b[0m to immediately \u001b[0;31mgive\u001b[0m \u001b[0;31mit\u001b[0m to the investigators , '' \u001b[0;32mhe\u001b[0m \u001b[0;32msays\u001b[0m .\n",
      "Score: (77.77777777777777, 11.11111111111111, 11.11111111111111)\n",
      "Avg copy length: 6.1\n",
      "===========================================================================================\n",
      "===========================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================\n",
      "Src 1: membership gives the icc jurisdiction over alleged crimes committed in palestinian territories since last june . israel and the united states opposed the move , which could open the door to war crimes investigations against israelis . ( cnn ) the palestinian \u001b[0;32mauthority\u001b[0m officially \u001b[0;32mbecame\u001b[0m the 123rd member of the international criminal court on wednesday , a step that gives the court jurisdiction over alleged crimes in palestinian territories . the formal \u001b[0;32maccession\u001b[0m was \u001b[0;32mmarked\u001b[0m with a ceremony at the hague , in the netherlands , where the court is based . the \u001b[0;32mpalestinians\u001b[0m \u001b[0;32msigned\u001b[0m the icc 's founding rome \u001b[0;32mstatute\u001b[0m in january , when they also accepted its jurisdiction over alleged crimes committed ` ` in the occupied palestinian territory , including east jerusalem , since june 13 , 2014 . ' ' later that month , the \u001b[0;32micc\u001b[0m \u001b[0;32mopened\u001b[0m a preliminary \u001b[0;32mexamination\u001b[0m into the situation in palestinian territories , paving the way for possible war crimes investigations against israelis . as members of the court , palestinians may be subject to counter - charges as well . israel and the united states , neither of which is an icc member , opposed the palestinians ' efforts to join the body . but palestinian foreign minister riad al - malki , speaking at wednesday 's ceremony , said it was a move toward greater justice . ` ` as palestine formally becomes a state party to the rome statute today , the world is also a step closer to ending a long era of impunity and injustice , '' he said , according to an icc news release . ` ` indeed , today brings us closer to our shared goals of justice and peace . ' ' judge kuniko ozaki , a vice president of the icc , said acceding to the treaty was just the first step for the palestinians . ` ` as the rome statute today enters into force for the state of palestine , palestine acquires all the rights as well as responsibilities that come with being a state party to the statute . these are substantive commitments , which can not be taken lightly , '' she said . rights group human rights watch welcomed the development . ` ` governments seeking to penalize palestine for joining the icc should immediately end their pressure , and countries that support universal acceptance of the court 's treaty should speak out to welcome its membership , '' said balkees jarrah , international justice counsel for the group . ` ` what 's objectionable is the attempts to undermine international justice , not palestine 's decision to join a treaty to which over 100 countries around the world are members . ' ' in january , when the preliminary icc examination was opened , israeli prime minister benjamin netanyahu described it as an outrage , saying the court was overstepping its boundaries . the united states also said it ` ` strongly ' ' disagreed with the court 's decision . ` ` as we have said repeatedly , we do not believe that palestine is a state and therefore we do not believe that it is eligible to join the icc , '' the state department said in a statement . it urged the warring sides to resolve their differences through direct negotiations . ` ` we will continue to oppose actions against israel at the icc as counterproductive to the cause of peace , '' it said . but the icc begs to differ with the definition of a state for its purposes and refers to the territories as ` ` palestine . ' ' while a preliminary examination is not a formal investigation , it allows the court to review evidence and determine whether to investigate suspects on both sides . prosecutor fatou bensouda said her office would ` ` conduct its analysis in full independence and impartiality . ' ' the war between israel and hamas militants in gaza last summer left more than 2,000 people dead . the inquiry will include alleged war crimes committed since june . the international criminal court was set up in 2002 to prosecute genocide , crimes against humanity and war crimes . cnn 's vasco cotovio , kareem khadder and faith karimi contributed to this report .\n",
      "===========================================================================================\n",
      "Summary 1: palestinian \u001b[0;32mauthority\u001b[0m officially \u001b[0;32mbecame\u001b[0m the 123rd member of the international criminal court . the formal \u001b[0;32maccession\u001b[0m was \u001b[0;32mmarked\u001b[0m with a ceremony at the hague . \u001b[0;32mpalestinians\u001b[0m \u001b[0;32msigned\u001b[0m the icc 's founding rome \u001b[0;32mstatute\u001b[0m in january . \u001b[0;32micc\u001b[0m \u001b[0;32mopened\u001b[0m a preliminary \u001b[0;32mexamination\u001b[0m into the situation in palestinian territories .\n",
      "Score: (100.0, 0.0, 0.0)\n",
      "Avg copy length: 7.142857142857143\n",
      "===========================================================================================\n",
      "===========================================================================================\n",
      "===========================================================================================\n",
      "Src 2: college - bound basketball star asks girl with down syndrome to high school prom . pictures of the two during the ` ` prom - posal ' ' have gone viral . ( cnn ) he 's a blue chip college basketball recruit . she 's a high school freshman with down syndrome . at first glance trey moses and ellie \u001b[0;33mmeredith\u001b[0m could n't \u001b[0;33mbe\u001b[0m more different . but all that changed thursday when \u001b[0;33mtrey\u001b[0m \u001b[0;33masked\u001b[0m \u001b[0;33mellie\u001b[0m to \u001b[0;33mbe\u001b[0m his prom date . trey -- a star on eastern high school 's basketball team in louisville , kentucky , who 's headed to play college ball next year at ball state -- \u001b[0;33mwas\u001b[0m originally going to take his girlfriend to eastern 's prom . so why is he taking ellie instead ? ` ` she 's great ... she listens and she 's easy to talk to ' ' he said . \u001b[0;32mtrey\u001b[0m \u001b[0;32mmade\u001b[0m the prom - posal ( yes , that 's what they are calling invites to prom these days ) in the gym during ellie 's p.e . class . trina \u001b[0;32mhelson\u001b[0m , a teacher at eastern , \u001b[0;32malerted\u001b[0m the school 's newspaper \u001b[0;32mstaff\u001b[0m to the prom - posal and posted photos of trey and ellie on twitter that have gone viral . she \u001b[0;33mwas\u001b[0m n't surpristed by trey 's actions . ` ` that 's the kind of person trey is , '' she said . to help make sure she said yes , trey entered the gym armed with flowers and a poster that read ` ` let 's party like it 's 1989 , '' a reference to the latest album by taylor swift , ellie 's favorite singer . trey also got the ok from ellie 's parents the night before via text . they were thrilled . ` ` you just feel numb to those moments raising a special needs child , '' said darla meredith , ellie 's mom . ` ` you first feel the need to protect and then to overprotect . ' ' darla meredith said ellie has struggled with friendships since elementary school , but a special program at eastern called best buddies had made things easier for her . she said best buddies cultivates friendships between students with and without developmental disabilities and prevents students like ellie from feeling isolated and left out of social functions . ` ` i guess around middle school is when kids started to care about what others thought , '' she said , but ` ` this school , this year has been a relief . ' ' trey 's future coach at ball state , james whitford , said he felt great about the prom - posal , noting that trey , whom he 's known for a long time , often works with other kids . trey 's \u001b[0;33mmother\u001b[0m , shelly moses , \u001b[0;33mwas\u001b[0m also proud of her son . ` ` it 's exciting to bring awareness to a good cause , '' she said . ` ` trey has worked pretty hard , and he 's a good son . ' ' both trey and ellie have a lot of planning to do . trey is looking to take up special education as a college major , in addition to playing basketball in the fall . as for ellie , she ca n't stop thinking about prom . ` ` ellie ca n't wait to go dress shopping ' ' her mother said . ` ` because i 've only told about a million people ! '' ellie interjected .\n",
      "===========================================================================================\n",
      "Summary 2: trey \u001b[0;33mmoses\u001b[0m and ellie meredith could n't \u001b[0;33mbe\u001b[0m more different . \u001b[0;33mtrey\u001b[0m \u001b[0;33mwas\u001b[0m a star on eastern high school 's basketball team in louisville , kentucky . trina \u001b[0;32mhelson\u001b[0m , a teacher at eastern , \u001b[0;32malerted\u001b[0m the school 's newspaper \u001b[0;32mstaff\u001b[0m . \u001b[0;32mtrey\u001b[0m \u001b[0;32mmade\u001b[0m the prom - posal 's\n",
      "Score: (50.0, 50.0, 0.0)\n",
      "Avg copy length: 7.333333333333333\n",
      "===========================================================================================\n",
      "===========================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================\n",
      "Src 3: don mclean 's ` ` american pie ' ' lyrics auctioned for $ 1.2 million . the song is dense with symbolism ; mclean says lyrics , notes will reveal meaning . ` ` pie ' ' is mclean 's biggest hit , was no . 1 in 1972 . ( cnn ) that 's some rich ` ` american pie . ' ' the lyrics to the famed don mclean song \u001b[0;33msold\u001b[0m for $ 1.2 million tuesday morning at an auction held by christie 's . ` ` don mclean 's \u001b[0;32mmanuscript\u001b[0m of ' american pie ' \u001b[0;32machieved\u001b[0m the 3rd highest auction \u001b[0;32mprice\u001b[0m for an american literary manuscript , a fitting \u001b[0;32mtribute\u001b[0m to one the foremost singer - songwriters of his generation , '' christie 's tom lecky said in a statement . \u001b[0;32mmclean\u001b[0m \u001b[0;32mtold\u001b[0m rolling \u001b[0;32mstone\u001b[0m that \u001b[0;32mit\u001b[0m \u001b[0;32mwas\u001b[0m time to part with the manuscript . ` ` i 'm going to be 70 this year , '' the singer and songwriter said in february . ` ` i have two children and a wife , and none of them seem to have the mercantile instinct . i want to get the best deal that i can for them . it 's time . ' ' over the years , ` ` american \u001b[0;32mpie\u001b[0m ' ' has \u001b[0;32mbecome\u001b[0m one of the most dissected and argued - about songs in the pop music canon . mclean has said that the opening lines were inspired by the death of buddy holly , but after that , it 's all been conjecture -- which has n't stopped a marching band 's worth of analysts from trying to parse the symbols in the 8-minute , 33-second opus . is the jester bob dylan ? the football game vietnam ? the ` ` girl who sang the blues ' ' janis joplin ? ( one thing 's certain : buddy holly 's plane was not named ` ` american pie . ' ' ) ` ` over the years i 've dealt with all these stupid questions of ' who 's that ? ' and ' who 's that ? ' ` ` mclean said . ` ` these are things i never had in my head for a second when i wrote the song . i was trying to capture something very ephemeral and i did , but it took a long time . ' ' the song catapulted the former folk singer to headliner status . the song hit no . 1 in early 1972 , despite its length . ( the 45-rpm single split the song in half on its a and b sides . ) the draft that was auctioned is 16 pages : 237 lines of manuscript and 26 lines of typed text , according to christie 's . it includes lines that did n't make the final version as well as extensive notes -- all of which should be revealing , mclean said . the record for a popular music manuscript is held by bob dylan 's ` ` like a rolling stone , '' \u001b[0;33mwhich\u001b[0m \u001b[0;33msold\u001b[0m for $ 2 million in june . opinion : what 's so great about ' american pie ' ?\n",
      "===========================================================================================\n",
      "Summary 3: the \u001b[0;33mlyrics\u001b[0m \u001b[0;33msold\u001b[0m for $ 1.2 million tuesday morning . the \u001b[0;32mmanuscript\u001b[0m of ` american pie ' \u001b[0;32machieved\u001b[0m the 3rd highest auction \u001b[0;32mprice\u001b[0m for an american literary . ` ` american \u001b[0;32mpie\u001b[0m ' ' has \u001b[0;32mbecome\u001b[0m one of the most dissected songs in the pop music canon . \u001b[0;32mmclean\u001b[0m \u001b[0;32mtold\u001b[0m rolling \u001b[0;32mstone\u001b[0m that \u001b[0;32mit\u001b[0m \u001b[0;32mwas\u001b[0m time to part with manuscript .\n",
      "Score: (80.0, 20.0, 0.0)\n",
      "Avg copy length: 4.9\n",
      "===========================================================================================\n",
      "===========================================================================================\n",
      "===========================================================================================\n",
      "Src 4: gov . mike \u001b[0;32mpence\u001b[0m \u001b[0;33mis\u001b[0m \u001b[0;32mmaking\u001b[0m the right \u001b[0;32mcall\u001b[0m to fix indiana 's religious freedom law , which can be used for discrimination . mark goldfeder : indiana should aim to be a shining beacon of cooperation : the real ` ` crossroads of america ' '\n",
      "===========================================================================================\n",
      "Summary 4: gov . mike \u001b[0;33mpence\u001b[0m \u001b[0;33msays\u001b[0m the state will ` ` fix ' ' the religious freedom act . pence : \u001b[0;32mpence\u001b[0m is \u001b[0;32mmaking\u001b[0m the right \u001b[0;32mcall\u001b[0m . in general , \u001b[0;33mit\u001b[0m \u001b[0;33mis\u001b[0m a good thing for \u001b[0;33msociety\u001b[0m to \u001b[0;33mshape\u001b[0m its \u001b[0;33mlaws\u001b[0m in ways \u001b[0;33mthat\u001b[0m \u001b[0;33mallow\u001b[0m \u001b[0;33mpeople\u001b[0m to \u001b[0;33mlive\u001b[0m their \u001b[0;33mlives\u001b[0m consistent with their sincerely held religious obligations indiana 's \u001b[0;33mrfra\u001b[0m \u001b[0;33mis\u001b[0m to \u001b[0;33madd\u001b[0m one \u001b[0;33mamendment\u001b[0m , one easy line codifying that \u001b[0;33mdiscrimination\u001b[0m against the lgbt community \u001b[0;33mis\u001b[0m harmful .\n",
      "Score: (12.5, 87.5, 0.0)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2d3a51b54e33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Summary {i}:\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolored_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mavg_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_copy_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_src_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Avg copy length:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===========================================================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c4d9a5dcd46d>\u001b[0m in \u001b[0;36mavg_copy_length\u001b[0;34m(src, gen)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#                 print(len(substrings[ixgw][0][0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mavg_length\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstrings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mixgw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mavg_length\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnum_copied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "src_path = \"data/fast-abs-RL/articles.txt\"\n",
    "tgt_path = \"data/fast-abs-RL/reference.txt\"\n",
    "gen_path = \"data/fast-abs-RL/decoded.txt\"\n",
    "\n",
    "line_num = 0 \n",
    "scores = []\n",
    "src_lines = []\n",
    "tgt_lines = []\n",
    "gen_lines = []\n",
    "with open(src_path) as src:\n",
    "    with open(tgt_path) as tgt:\n",
    "        with open(gen_path) as gen:\n",
    "            for i, (orig_src_line, orig_tgt_line, gen_line) in enumerate(zip(src, tgt, gen)):\n",
    "    #             if i < 30:\n",
    "    #                 continue\n",
    "                if line_num > 0 and not i == line_num:\n",
    "                    continue\n",
    "                if line_num == 0 and i >= 40:\n",
    "                    break\n",
    "                orig_src_line = clean_src(orig_src_line)\n",
    "                orig_tgt_line = clean_src(orig_tgt_line)\n",
    "                src_line = orig_tgt_line + ' ' + orig_src_line\n",
    "                src_lines.append(orig_src_line)\n",
    "                tgt_lines.append(orig_tgt_line)\n",
    "                gen_line = clean_gen(gen_line)\n",
    "                gen_lines.append(gen_line)\n",
    "                important_relations, score, (colored_src, colored_gen) = test(src_line, gen_line)\n",
    "                print(\"===========================================================================================\")\n",
    "                print(f\"Src {i}:\"%{i:i}, colored_src)\n",
    "                print(\"===========================================================================================\")\n",
    "                print(f\"Summary {i}:\"%{i:i}, colored_gen)\n",
    "                print(\"Score:\", score)\n",
    "                avg_length = avg_copy_length(orig_src_line, gen_line)\n",
    "                print(\"Avg copy length:\", avg_length)\n",
    "                print(\"===========================================================================================\")\n",
    "                print(\"===========================================================================================\")\n",
    "                scores.append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-83f3dcab74e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdep_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for token in nlp(src_lines[0]):\n",
    "    print(token, token.dep_, token.pos_, token.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lara compound PROPN logan\n",
      "logan nsubj NOUN is\n",
      "is ROOT VERB is\n",
      "back advmod ADV home\n",
      "home advmod ADV is\n",
      "and cc CCONJ is\n",
      "recovering conj VERB is\n",
      "after mark ADP checked\n",
      "she nsubj PRON checked\n",
      "reportedly advmod ADV checked\n",
      "checked advcl VERB recovering\n",
      "into prep ADP checked\n",
      "a det DET hospital\n",
      "dc compound ADJ hospital\n",
      "hospital pobj NOUN into\n",
      "for prep ADP checked\n",
      "at advmod ADV least\n",
      "least advmod ADJ time\n",
      "the det DET time\n",
      "fourth amod ADJ time\n",
      "time pobj NOUN for\n",
      "this det DET year\n",
      "year npadvmod NOUN time\n",
      ". punct PUNCT is\n",
      "she nsubjpass PRON assaulted\n",
      "was auxpass VERB assaulted\n",
      "brutally advmod ADV sexually\n",
      "sexually advmod ADV assaulted\n",
      "assaulted ROOT VERB assaulted\n",
      "while mark ADP reporting\n",
      "reporting advcl VERB assaulted\n",
      "in prep ADP reporting\n",
      "egypt pobj PROPN in\n",
      "in prep ADP reporting\n",
      "2011 pobj NUM in\n",
      ". punct PUNCT assaulted\n",
      "she nsubjpass PRON rescued\n",
      "was auxpass VERB rescued\n",
      "rescued ROOT VERB rescued\n",
      "by agent ADP rescued\n",
      "a det DET mob\n",
      "mob pobj NOUN by\n",
      "of prep ADP mob\n",
      "200 nummod NUM men\n",
      "- punct SYM 300\n",
      "300 nummod NUM men\n",
      "men pobj NOUN of\n",
      "after mark ADP reporting\n",
      "she nsubj PRON reporting\n",
      "was aux VERB reporting\n",
      "reporting advcl VERB rescued\n",
      "from prep ADP reporting\n",
      "cairo pobj NOUN from\n",
      "on prep ADP reporting\n",
      "the det DET resignation\n",
      "resignation pobj NOUN on\n",
      "of prep ADP resignation\n",
      "president compound NOUN mubarak\n",
      "mubarak pobj NOUN of\n",
      ". punct PUNCT rescued\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(gen_lines[0]):\n",
    "    print(token, token.dep_, token.pos_, token.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.load(\"sandbox/scores.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(scores[:,0], scores[:,2], marker='.')\n",
    "plt.xlabel(\"% contained\")\n",
    "plt.ylabel(\"% contradiction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(gen_lines[0], tgt_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.41999999503200003,\n",
       "   'p': 0.45652173913043476,\n",
       "   'r': 0.3888888888888889},\n",
       "  'rouge-2': {'f': 0.18032786393845757,\n",
       "   'p': 0.20754716981132076,\n",
       "   'r': 0.15942028985507245},\n",
       "  'rouge-l': {'f': 0.4147252747249494,\n",
       "   'p': 0.45652173913043476,\n",
       "   'r': 0.3888888888888889}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.get_scores(gen_lines[1], tgt_lines[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying BERT embeddings...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relations between iran and saudi arabia have always been thorny , but rarely has the state of affairs been as venomous as it is today',\n",
       " 'tehran and riyadh each point to the other as the main reason for much of the turmoil in the middle east',\n",
       " 'in its most recent incarnation , the iranian-saudi conflict by proxy has reached yemen in a spiral that both sides portray as climatic',\n",
       " \"for riyadh and its regional allies , the saudi military intervention in yemen -- `` operation decisive storm'' -- is the moment the sunni arab nation finally woke up to repel the expansion of shia-iranian influence\",\n",
       " \"for tehran and its regional allies -- including the houthi movement in yemen -- saudi arabia's actions are in defense of a retrogressive status quo order that is no longer tenable\",\n",
       " 'and yet both sides have good reasons to want to stop the yemeni crisis from spiraling out of control and evolving into an unwinnable war',\n",
       " 'when iranian president hassan rouhani was elected in june 2013 , he pledged to reach out to riyadh',\n",
       " \"he was up front and called tehran's steep deterioration of relations with the saudis over the last decade as one of the principal burdens on iranian foreign policy\",\n",
       " 'from lebanon and afghanistan to pakistan and the gaza strip , the iranian-saudi rivalry and conflict through proxy has been deep and costly',\n",
       " \"and yet despite rouhani's open pledge , profound differences over syria and iraq in particular have kept riyadh and tehran apart\",\n",
       " 'but if the questions of syria and iraq prevented a pause in hostilities , the saudi military intervention in yemen since late march has all but raised the stakes to unprecedentedly dangerous levels',\n",
       " 'unlike in syria and in iraq , the saudi military is now directly battling it out with iranian-backed rebels in yemen',\n",
       " \"while riyadh no doubt exaggerates tehran's role in the yemen crisis , its fingerprints are nonetheless evident\",\n",
       " \"`` iran provides financial support , weapons , training and intelligence to houthis ,'' gerald feierstein , a u.s. state department official and former yemen ambassador , told a congressional hearing last week\",\n",
       " '`` we believe that iran sees opportunities with the houthis to expand its influence in yemen and threaten saudi and gulf arab']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embedding = BertEmbedding()\n",
    "embed = bert_embedding(src_lines[0].split(' . '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['relations',\n",
       " 'between',\n",
       " 'iran',\n",
       " 'and',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'have',\n",
       " 'always',\n",
       " 'been',\n",
       " 'thorny',\n",
       " ',',\n",
       " 'but',\n",
       " 'rarely',\n",
       " 'has',\n",
       " 'the',\n",
       " 'state',\n",
       " 'of',\n",
       " 'affairs',\n",
       " 'been',\n",
       " 'as',\n",
       " 'venomous']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(embed[0][1])):\n",
    "#     plt.scatter([embed[0][1][i][0]], [embed[0][1][i][1]], label=embed[0][0][i])\n",
    "# # plt.scatter([embed[0][1][i][0] for i in range(len(embed[0][1]))], \n",
    "# #             [embed[0][1][i][1] for i in range(len(embed[0][1]))])\n",
    "# # plt.scatter([embed[0][1][2][0]], [embed[0][1][2][1]])\n",
    "# # plt.scatter([embed[0][1][4][0]], [embed[0][1][4][1]])\n",
    "# # plt.scatter([embed[0][1][5][0]], [embed[0][1][5][1]])\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.376158"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(embed[0][1][4] - embed[0][1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab file is not found. Downloading.\n",
      "Downloading /Users/cliang/.mxnet/models/book_corpus_wiki_en_uncased-a6607397.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/book_corpus_wiki_en_uncased-a6607397.zip...\n",
      "Downloading /Users/cliang/.mxnet/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip...\n"
     ]
    }
   ],
   "source": [
    "bert_embedding = BertEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "with open(\"data/test.txt.src.tagged.shuf.400words\") as src:\n",
    "    with open(\"data/bottom_up_cnndm_015_threshold.out\") as gen:\n",
    "        for src_line0, gen_line0 in zip(src, gen):\n",
    "            if(i >= 8):\n",
    "                break\n",
    "#             print(src_line0)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = gen_line.split(' . ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bert_embedding([\"I ate a dog\", \"I ate a cat\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'ate', 'a', 'dog']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3448873"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(result[1][1][3]- result[0][1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9955516"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(result[1][1][1]- result[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
